index_pre_order = order(new_surplus, decreasing = F)
pre_optimum_coefficients = pre_optimum_coefficients[index_pre_order[1:5],]
pre_surplus = pre_surplus[index_pre_order[1:5]]
pre_payback = pre_payback[index_pre_order[1:5], ]
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index_new_order = order(new_surplus, decreasing = F)
optimum_coefficients = new_optimum_coefficients[index_new_order[1:5],]
surplus = new_surplus[index_new_order[1:5]]
payback = new_payback[index_new_order[1:5], ]
pre_optimum_coefficients
optimum_coefficients
pre_surplus
surplus
surplus = new_surplus[index_new_order]
surplus
plot(surplus)
surplus = surplus[surplus < 1000000]
surplus
plot(surplus)
ggplot(aes(x = 1:length(surplus), y = surplus))
ggplot() + geom_point(aes(x = 1:length(surplus), y = surplus))
index_new_order
payback_ideal = 4
cost_payback = sum(exp(payback_years - payback_ideal))
cost_payback = sum(exp(payback - payback_ideal))
cost_payback = sum(exp(payback - payback_ideal))
cost_payback
ggplot() + geom_point(aes(x = cost_payback, y = surplus))
exp(payback - payback_ideal)
payback = new_payback[index_new_order, ]
payback = payback[surplus < 1000000, ]
payback
cost_payback = rowSums(exp(payback - payback_ideal))
cost_payback
ggplot() + geom_point(aes(x = cost_payback, y = surplus))
surplus = new_surplus[index_new_order]
surplus = surplus[surplus < 1000000]
surplus
payback = new_payback[index_new_order, ]
payback = payback[surplus < 1000000, ]
payback
payback_ideal = 4
cost_payback = rowSums(exp(payback - payback_ideal))
cost_payback
length(cost_payback)
length(surplus)
which(surplus < 1000000)
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
which(surplus < 1000000)
index_new_order = order(new_surplus, decreasing = F)
index_new_order
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index_new_order = order(new_surplus, decreasing = F)
index_new_order
index_new_order = index_new_order[surplus < 1000000]
index_new_order
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index = order(new_surplus, decreasing = F)
index = index_new_order[new_surplus < 1000000]
index
order(new_surplus, decreasing = F)
new_surplus = new_surplus[index]
new_payback = new_payback[index, ]
payback_ideal = 4
cost_payback = rowSums(exp(payback - payback_ideal))
cost_payback
nrow(cost_payback)
length(cost_payback)
length(new_surplus)
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
new_surplus
length(cost_payback)
length(new_surplus)
nrow(new_payback)
new_surplus = new_surplus[index]
new_payback = new_payback[index, ]
payback_ideal = 4
cost_payback = rowSums(exp(new_payback - payback_ideal))
nrow(cost_payback)
length(cost_payback)
length(new_surplus)
ggplot() + geom_point(aes(x = cost_payback, y = surplus))
new_surplus = new_surplus[cost_payback < 2.5, ]
new_payback = new_payback[cost_payback < 2.5, ]
new_surplus = new_surplus[cost_payback < 2.5]
new_payback = new_payback[cost_payback < 2.5, ]
ggplot() + geom_point(aes(x = cost_payback, y = surplus))
cost_payback = rowSums(exp(new_payback - payback_ideal))
ggplot() + geom_point(aes(x = cost_payback, y = surplus))
cost_payback
ggplot() + geom_point(aes(x = cost_payback, y = new_surplus))
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index = order(new_surplus, decreasing = F)
index = index_new_order[new_surplus < 1000000]
new_surplus = new_surplus[index]
new_payback = new_payback[index, ]
payback_ideal = 4
cost_payback = rowSums(exp(new_payback - payback_ideal))
ggplot() + geom_point(aes(x = 1:length(new_surplus), y = new_surplus))
ggplot() + geom_point(aes(x = cost_payback, y = new_surplus))
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index = order(new_surplus, decreasing = F)
index = index_new_order[new_surplus < 1000000]
new_surplus = new_surplus[index]
ggplot() + geom_point(aes(x = 1:length(new_surplus), y = new_surplus))
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index = order(new_surplus, decreasing = F)
index = index_new_order[new_surplus < 1000000]
new_surplus = new_surplus[index]
new_payback = new_payback[index, ]
payback_ideal = 4
cost_payback = rowSums(exp(new_payback - payback_ideal))
ggplot() + geom_point(aes(x = 1:length(new_surplus), y = new_surplus))
which(new_surplus < 1000000)
index = order(new_surplus, decreasing = F)[order(new_surplus, decreasing = F) %in% which(new_surplus < 1000000)]
index
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index = order(new_surplus, decreasing = F)[order(new_surplus, decreasing = F) %in% which(new_surplus < 1000000)]
index
new_surplus = new_surplus[index]
new_payback = new_payback[index, ]
payback_ideal = 4
cost_payback = rowSums(exp(new_payback - payback_ideal))
ggplot() + geom_point(aes(x = 1:length(new_surplus), y = new_surplus))
ggplot() + geom_point(aes(x = cost_payback, y = new_surplus))
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
# import libraries
library(lubridate)
library(ggplot2)
library(ggpubr)
library(reshape2)
library(GA)
library(parallel)
library(purrr)
# and functions
source("functions_new.R")
##########################################################################################################
# example
filename_gen_1 = "data/202005081411_charts_compare.csv"
# cons_1 is too high
filename_cons_1 = "data/202005081413_charts_compare.csv"
filename_cons_2 = "data/202005081655_charts_compare.csv"
filename_cons_3 = "data/202005081656_charts_compare.csv"
filename_cons_4 = "data/202005081658_charts_compare.csv"
# new:
filename_cons_5 = "data/202103171643_charts_historic.csv"
# gen_5 is too low
filename_gen_5 = "data/202103171649_charts_historic.csv"
filename_cons_6 = "data/202103171657_charts_historic.csv"
# gen_7 is too low
filename_gen_7 = "data/202103171735_charts_historic_generation.csv"
filename_cons_7 = "data/202103171735_charts_historic_cons.csv"
filename_cons_8 = "data/202103171814_charts_historic.csv"
filename_cons_9 = "data/202103171831_charts_historic.csv"
filename_cons_10 = "data/202103171835_charts_historic.csv"
# gen_10 is too low
filename_gen_10 = "data/202103171838_charts_historic.csv"
filename_cons_11 = "data/202103171858_charts_historic.csv"
filename_cons_12 = "data/202103171905_charts_historic.csv"
filename_cons_13 = "data/202103181018_charts_historic.csv"
filename_cons_14 = "data/202103181023_charts_historic.csv"
filename_cons_15 = "data/202103181029_charts_historic.csv"
filename_cons_16 = "data/202103181032_charts_historic.csv"
filename_cons_17 = "data/202103181037_charts_historic.csv"
filename_cons_18 = "data/202103181040_charts_historic.csv"
# TODO:
# cons_1 y gen_1 corresponden al museo de diseño de barcelona -> son muy altos comparados al resto
# la instalación es realmente muy grande
# y el consumo base en enorme (porque es un museo enorme), con lo cual la instalación, por más de que sea enorme, no llega a cubrir los consumos del propio edificio
# (no es autosuficiente)--> qué sentido tiene repartir la energía?
# con lo cual --> escenario fake: voy a usar la generación y no voy a usar el consumo del museo
# TODO: ojo! la instalación que estoy considerando tiene mas de 100kWh... la legislación no lo permite
filenames_list = list(filename_gen_1, filename_cons_2, filename_cons_3, filename_cons_4, filename_cons_5, filename_cons_6, filename_cons_7, filename_cons_8, filename_cons_9, filename_cons_11, filename_cons_12, filename_cons_13, filename_cons_14, filename_cons_15, filename_cons_16, filename_cons_17, filename_cons_18)
df = lapply(X = filenames_list, FUN = import_one_user)
df_month_1 = select_month(df, m=7)
df_month_1 = eliminate_outliers(df_month_1)
df_month_1 = reducing_consumption_fake(df_month_1)
p = initial_plot(df_month_1)
df_gen = data.frame("gen_1" = df_month_1[, "gen_1"])
df_cons = df_month_1[, grep(pattern = "cons", x = colnames(df_month_1))]
# TODO:
# changing NAs to 0
df_gen[is.na(df_gen)] = 0
df_cons[is.na(df_cons)] = 0
# Size of the proposed community
# TODO: This "size of the community" should be determined by something related to the maximum of df_gen
# now it is set to be fixed, should be a maximum.. should change the place where the coefficients are calculated
# TODO: working here, should order my ideas! what do I want to calculate?
# should always summer months to calculate the community max
n_community_max = calculate_n_community_max(generation = df_gen$gen_1, df_cons, time = df_month_1$time)
n_community_max = 6
# TODO
# a good estimation of the overall investment is:
# 1000*kWpico
# if the max consumption is in summer I can approximate:
global_investment = max(df[[1]]$energy, na.rm = T)*1100
#######################################################################################
n_binary_rep = log(ncol(df_cons), base=2)
# TODO: should change this
individual_investment = sapply(df_cons, max, na.rm = TRUE)*1100
# should always summer months to calculate the community max
n_community_max = calculate_n_community_max(generation = df_gen$gen_1, df_cons, time = df_month_1$time)
n_community_max
n_community_max = 6
# TODO
# a good estimation of the overall investment is:
# 1000*kWpico
# if the max consumption is in summer I can approximate:
global_investment = max(df[[1]]$energy, na.rm = T)*1100
global_investment
#######################################################################################
n_binary_rep = log(ncol(df_cons), base=2)
n_binary_rep
df_cons
cbind(df_cons, df_cons)
rep("cons_", 16)
paste(rep("cons_", 16), 16:32)
17:32
length(17:32)
colnames(df_cons) = paste(rep("cons_", 16), 17:32)
colnames(df_cons)
df_cons
# import libraries
library(lubridate)
library(ggplot2)
library(ggpubr)
library(reshape2)
library(GA)
library(parallel)
library(purrr)
# and functions
source("functions_new.R")
##########################################################################################################
# example
filename_gen_1 = "data/202005081411_charts_compare.csv"
# cons_1 is too high
filename_cons_1 = "data/202005081413_charts_compare.csv"
filename_cons_2 = "data/202005081655_charts_compare.csv"
filename_cons_3 = "data/202005081656_charts_compare.csv"
filename_cons_4 = "data/202005081658_charts_compare.csv"
# new:
filename_cons_5 = "data/202103171643_charts_historic.csv"
# gen_5 is too low
filename_gen_5 = "data/202103171649_charts_historic.csv"
filename_cons_6 = "data/202103171657_charts_historic.csv"
# gen_7 is too low
filename_gen_7 = "data/202103171735_charts_historic_generation.csv"
filename_cons_7 = "data/202103171735_charts_historic_cons.csv"
filename_cons_8 = "data/202103171814_charts_historic.csv"
filename_cons_9 = "data/202103171831_charts_historic.csv"
filename_cons_10 = "data/202103171835_charts_historic.csv"
# gen_10 is too low
filename_gen_10 = "data/202103171838_charts_historic.csv"
filename_cons_11 = "data/202103171858_charts_historic.csv"
filename_cons_12 = "data/202103171905_charts_historic.csv"
filename_cons_13 = "data/202103181018_charts_historic.csv"
filename_cons_14 = "data/202103181023_charts_historic.csv"
filename_cons_15 = "data/202103181029_charts_historic.csv"
filename_cons_16 = "data/202103181032_charts_historic.csv"
filename_cons_17 = "data/202103181037_charts_historic.csv"
filename_cons_18 = "data/202103181040_charts_historic.csv"
# TODO:
# cons_1 y gen_1 corresponden al museo de diseño de barcelona -> son muy altos comparados al resto
# la instalación es realmente muy grande
# y el consumo base en enorme (porque es un museo enorme), con lo cual la instalación, por más de que sea enorme, no llega a cubrir los consumos del propio edificio
# (no es autosuficiente)--> qué sentido tiene repartir la energía?
# con lo cual --> escenario fake: voy a usar la generación y no voy a usar el consumo del museo
# TODO: ojo! la instalación que estoy considerando tiene mas de 100kWh... la legislación no lo permite
filenames_list = list(filename_gen_1, filename_cons_2, filename_cons_3, filename_cons_4, filename_cons_5, filename_cons_6, filename_cons_7, filename_cons_8, filename_cons_9, filename_cons_11, filename_cons_12, filename_cons_13, filename_cons_14, filename_cons_15, filename_cons_16, filename_cons_17, filename_cons_18)
df = lapply(X = filenames_list, FUN = import_one_user)
df_month_1 = select_month(df, m=7)
df_month_1 = eliminate_outliers(df_month_1)
df_month_1 = reducing_consumption_fake(df_month_1)
p = initial_plot(df_month_1)
df_gen = data.frame("gen_1" = df_month_1[, "gen_1"])
df_cons = df_month_1[, grep(pattern = "cons", x = colnames(df_month_1))]
# TODO:
# changing NAs to 0
df_gen[is.na(df_gen)] = 0
df_cons[is.na(df_cons)] = 0
# Size of the proposed community
# TODO: This "size of the community" should be determined by something related to the maximum of df_gen
# now it is set to be fixed, should be a maximum.. should change the place where the coefficients are calculated
# TODO: working here, should order my ideas! what do I want to calculate?
# should always summer months to calculate the community max
n_community_max = calculate_n_community_max(generation = df_gen$gen_1, df_cons, time = df_month_1$time)
n_community_max = 6
# TODO
# a good estimation of the overall investment is:
# 1000*kWpico
# if the max consumption is in summer I can approximate:
global_investment = max(df[[1]]$energy, na.rm = T)*1100
df_cons = cbind(df_cons, df_cons)
colnames(df_cons)
length(colnames(df_cons))
colnames(df_cons)[17:32] = paste(rep("cons_", 16),17:32)
df_cons
colnames(df_cons)[17:32] = paste0(rep("cons_", 16),17:32)
colnames(df_cons)
n_binary_rep = log(ncol(df_cons), base=2)
n_binary_rep
# TODO: should change this
individual_investment = sapply(df_cons, max, na.rm = TRUE)*1100
optimal_combination_using_2_GAs <- optimize_using_2_GAs_withBestSolutionSelection(n_community = n_community_max, n_binary_rep, df_gen, df_cons, global_investment, individual_investment)
n_community_max
# should always summer months to calculate the community max
n_community_max = calculate_n_community_max(generation = df_gen$gen_1, df_cons, time = df_month_1$time)
n_community_max
optimal_combination_using_2_GAs <- optimize_using_2_GAs_withBestSolutionSelection(n_community = n_community_max, n_binary_rep, df_gen, df_cons, global_investment, individual_investment)
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
optimal_combination_using_2_GAs <- optimize_using_2_GAs_withBestSolutionSelection(n_community_max = n_community_max, n_binary_rep, df_gen, df_cons, global_investment, individual_investment)
n_community_max
n_binary_rep
df_gen
df_cons
# TODO: understand the criteria of the keepBest = T
pre_optimal_combinations <- pre_optimization_for_nested(n_community_max, n_binary_rep, df_gen, df_cons)
optim_results <- ga(type = "binary", fitness = fitness,
nBits = n_binary_rep*n_community,
n_community = n_community, df_gen = df_gen, df_cons = df_cons,
# popSize = 100, maxiter = 1000, run = 100)
popSize = 200, maxiter = 100, run = 50,
crossover = purrr::partial(bee_uCrossover, n_binary_rep = n_binary_rep, n_community = n_community),
keepBest = T,
pmutation = 0.3
)
n_community
# TODO: understand the criteria of the keepBest = T
pre_optimal_combinations <- pre_optimization_for_nested(n_community = n_community_max, n_binary_rep = n_binary_rep, df_gen = df_gen, df_cons = df_cons)
n_community_max
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
# TODO: understand the criteria of the keepBest = T
pre_optimal_combinations <- pre_optimization_for_nested(n_community = n_community_max, n_binary_rep = n_binary_rep, df_gen = df_gen, df_cons = df_cons)
# import libraries
library(lubridate)
library(ggplot2)
library(ggpubr)
library(reshape2)
library(GA)
library(parallel)
library(purrr)
# and functions
source("functions_new.R")
##########################################################################################################
# example
filename_gen_1 = "data/202005081411_charts_compare.csv"
# cons_1 is too high
filename_cons_1 = "data/202005081413_charts_compare.csv"
filename_cons_2 = "data/202005081655_charts_compare.csv"
filename_cons_3 = "data/202005081656_charts_compare.csv"
filename_cons_4 = "data/202005081658_charts_compare.csv"
# new:
filename_cons_5 = "data/202103171643_charts_historic.csv"
# gen_5 is too low
filename_gen_5 = "data/202103171649_charts_historic.csv"
filename_cons_6 = "data/202103171657_charts_historic.csv"
# gen_7 is too low
filename_gen_7 = "data/202103171735_charts_historic_generation.csv"
filename_cons_7 = "data/202103171735_charts_historic_cons.csv"
filename_cons_8 = "data/202103171814_charts_historic.csv"
filename_cons_9 = "data/202103171831_charts_historic.csv"
filename_cons_10 = "data/202103171835_charts_historic.csv"
# gen_10 is too low
filename_gen_10 = "data/202103171838_charts_historic.csv"
filename_cons_11 = "data/202103171858_charts_historic.csv"
filename_cons_12 = "data/202103171905_charts_historic.csv"
filename_cons_13 = "data/202103181018_charts_historic.csv"
filename_cons_14 = "data/202103181023_charts_historic.csv"
filename_cons_15 = "data/202103181029_charts_historic.csv"
filename_cons_16 = "data/202103181032_charts_historic.csv"
filename_cons_17 = "data/202103181037_charts_historic.csv"
filename_cons_18 = "data/202103181040_charts_historic.csv"
# TODO:
# cons_1 y gen_1 corresponden al museo de diseño de barcelona -> son muy altos comparados al resto
# la instalación es realmente muy grande
# y el consumo base en enorme (porque es un museo enorme), con lo cual la instalación, por más de que sea enorme, no llega a cubrir los consumos del propio edificio
# (no es autosuficiente)--> qué sentido tiene repartir la energía?
# con lo cual --> escenario fake: voy a usar la generación y no voy a usar el consumo del museo
# TODO: ojo! la instalación que estoy considerando tiene mas de 100kWh... la legislación no lo permite
filenames_list = list(filename_gen_1, filename_cons_2, filename_cons_3, filename_cons_4, filename_cons_5, filename_cons_6, filename_cons_7, filename_cons_8, filename_cons_9, filename_cons_11, filename_cons_12, filename_cons_13, filename_cons_14, filename_cons_15, filename_cons_16, filename_cons_17, filename_cons_18)
df = lapply(X = filenames_list, FUN = import_one_user)
df_month_1 = select_month(df, m=7)
df_month_1 = eliminate_outliers(df_month_1)
df_month_1 = reducing_consumption_fake(df_month_1)
p = initial_plot(df_month_1)
df_gen = data.frame("gen_1" = df_month_1[, "gen_1"])
df_cons = df_month_1[, grep(pattern = "cons", x = colnames(df_month_1))]
# TODO:
# changing NAs to 0
df_gen[is.na(df_gen)] = 0
df_cons[is.na(df_cons)] = 0
# Size of the proposed community
# TODO: This "size of the community" should be determined by something related to the maximum of df_gen
# now it is set to be fixed, should be a maximum.. should change the place where the coefficients are calculated
# TODO: working here, should order my ideas! what do I want to calculate?
# should always summer months to calculate the community max
n_community_max = calculate_n_community_max(generation = df_gen$gen_1, df_cons, time = df_month_1$time)
n_community_max = 6
# TODO
# a good estimation of the overall investment is:
# 1000*kWpico
# if the max consumption is in summer I can approximate:
global_investment = max(df[[1]]$energy, na.rm = T)*1100
#######################################################################################
df_cons = cbind(df_cons, df_cons)
colnames(df_cons)[17:32] = paste0(rep("cons_", 16),17:32)
n_binary_rep = log(ncol(df_cons), base=2)
# TODO: should change this
individual_investment = sapply(df_cons, max, na.rm = TRUE)*1100
# checking:
# sum(sapply(df_cons, max, na.rm = TRUE)*1100) > global_investment
tic = Sys.time()
# TODO:
# why the first run has this error? is it still appearing?
# Error in gareal_lsSelection_Rcpp(object) :
#   Too few positive probabilities!
optimal_combination_using_2_GAs <- optimize_using_2_GAs_withBestSolutionSelection(n_community_max = n_community_max, n_binary_rep, df_gen, df_cons, global_investment, individual_investment)
toc = Sys.time()
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
combinations = t(apply(X = as.matrix(solutions), MARGIN = 1, FUN = calculate_combination_for_GA_binary, n_community = n_community, n_binary_rep = n_binary_rep))
# TODO: understand the criteria of the keepBest = T
pre_optimal_combinations <- pre_optimization_for_nested(n_community = n_community_max, n_binary_rep = n_binary_rep, df_gen = df_gen, df_cons = df_cons)
# TODO: separate the combinations according to the number n_community_per_combination
n_community_per_combination_order = order(rowSums(pre_optimal_combinations))
pre_optimal_combinations = pre_optimal_combinations[n_community_per_combination_order, ]
n_community_vector = rowSums(pre_optimal_combinations)
pre_optimum_coefficients = t((apply(X = pre_optimal_combinations, MARGIN = 1, FUN = calculate_coefficients, df_gen = df_gen, df_cons = df_cons)))
# but all of the coefficients sum 1
hourly_surplus = apply(X = pre_optimum_coefficients, MARGIN = 1, FUN = calculate_surplus_hourly_individual, df_gen = df_gen, df_cons = df_cons)
pre_surplus = as.numeric(lapply(X = hourly_surplus, FUN = sum))
new_optimum_coefficients = pre_optimum_coefficients
new_surplus = rep(0, nrow(pre_optimal_combinations))
new_payback = pre_optimum_coefficients
pre_payback = pre_optimum_coefficients
for (i in 1:nrow(pre_optimal_combinations)) {
combination_selected = pre_optimal_combinations[i, ]
df_cons_selected = df_cons[,combination_selected==1]
individual_investment_max = individual_investment[combination_selected==1]
coefficients = calculate_coefficients(df_gen = df_gen, df_cons = df_cons, combination = combination_selected)
# surplus_min_x = sum(calculate_surplus_hourly_individual(df_gen, df_cons, coefficients))
# if (sum(combination_selected) == n_community &
#     sum(individual_investment_max) > global_investment) {
if (sum(individual_investment_max) > global_investment) {
n_community = as.numeric(n_community_vector[i])
# x just selects the users, no need to calculate the optimum combination here
# I think calculating the coeffs should be inside the "inside GA"
# optimum_coefficients = calculate_coefficients(df_gen, df_cons, combination)
individual_investment_selected = calculate_individual_investment(combination_selected, global_investment, individual_investment_max)
# just checking
# if (any(individual_investment_selected > individual_investment_max)){
#   print("fail")
# }
pre_payback[i, combination_selected!=0] = calculate_payback(df_cons_selected, df_gen, individual_investment_selected, pre_optimum_coefficients[i,combination_selected!=0])
optim_results <- ga(type = "real-valued", fitness = fitness_nested_inside,
lower = array(0, dim = n_community), upper = array(1, dim = n_community),
df_gen = df_gen, df_cons_selected = df_cons_selected, combination = combination_selected,
individual_investment = individual_investment_selected,
popSize = 100, maxiter = 5, run = 5)
coefficients_optimum <- optim_results@solution[1, ]
coefficients_optimum = coefficients_optimum/sum(coefficients_optimum)
combination_optimum = combination_selected
combination_optimum[combination_optimum!=0] = coefficients_optimum
new_optimum_coefficients[i, ] = combination_optimum
new_payback[i, combination_selected!=0] = calculate_payback(df_cons_selected, df_gen, individual_investment_selected, new_optimum_coefficients[i,combination_selected!=0])
surplus = sum(calculate_surplus_hourly_individual(df_gen, df_cons, combination_optimum))
new_surplus[i] <- surplus
} else{
new_surplus[i] <- 1000000
}
}
# TODO: separate the combinations according to the number n_community_per_combination
n_community_per_combination_order = order(rowSums(pre_optimal_combinations))
pre_optimal_combinations = pre_optimal_combinations[n_community_per_combination_order, ]
n_community_vector = rowSums(pre_optimal_combinations)
results = list("pre_optimum_coefficients" = pre_optimum_coefficients,
"pre_surplus" = pre_surplus,
"pre_payback" = pre_payback,
"new_optimum_coefficients" = new_optimum_coefficients,
"new_surplus" = new_surplus,
"new_payback" = new_payback)
optimal_combination_using_2_GAs = results
new_optimum_coefficients = optimal_combination_using_2_GAs$new_optimum_coefficients
new_surplus = optimal_combination_using_2_GAs$new_surplus
new_payback = optimal_combination_using_2_GAs$new_payback
index = order(new_surplus, decreasing = F)[order(new_surplus, decreasing = F) %in% which(new_surplus < 1000000)]
new_surplus = new_surplus[index]
new_payback = new_payback[index, ]
payback_ideal = 4
cost_payback = rowSums(exp(new_payback - payback_ideal))
# TODO: study carefully this graph, does this make sense?
ggplot() + geom_point(aes(x = 1:length(new_surplus), y = new_surplus))
ggplot() + geom_point(aes(x = cost_payback, y = new_surplus))
source('~/Documents/projects/EKATE/transactive_energy_EKATE/functions_new.R')
